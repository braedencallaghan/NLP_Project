{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    # api_key=\"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\",\n",
    ")\n",
    "\n",
    "\n",
    "def getPrompt(N, examples):\n",
    "    PROMPT = (\n",
    "        \"\"\"\n",
    "    I am training a natural language processing model but dont have enough data. It is your job to generate more, new, and unique samples\n",
    "    of data like the ones pasted below. What you generate should be representitive of what might be found on twitter. Use appropriate slang, humor, and give a wide varity\n",
    "    of types of samples (i.e, talking about different topics). Pased below is a small representative sample which should inspire you, as well as their labels. Use the type of wording and writing style of \n",
    "    these tweets. Return *only* the requested JSON response, in the same format as below, with your assigned labels to your generated samples. I want you to generate {N} samples.\n",
    "\n",
    "    Your returned format should look like this:\n",
    "    {\n",
    "        'content of tweet 1': 'POS',\n",
    "        'content of tweet 2': 'NEG',\n",
    "        ...\n",
    "        \n",
    "    }\n",
    "    \n",
    "    Here is the representative sample of tweets. Please do not use emojis in your samples.\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        + f\"{examples}\"\n",
    "    )\n",
    "    return PROMPT\n",
    "\n",
    "\n",
    "def queryGPT(prompt):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "    return chat_completion.model_dump()[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"tweets.csv\", names=[\"label\", \"id\", \"date\", \"no_query\", \"user\", \"content\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(n=20)\n",
    "labels = map(lambda x: \"POS\" if x == 4 else \"NEG\", df_sample[\"label\"].to_list())\n",
    "contents = df_sample[\"content\"].to_list()\n",
    "samples = list(zip(labels, contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NEG', 'i think my twitter is broken '),\n",
       " ('POS',\n",
       "  \"trying to work out exctly how Twitter works...shouldn't take too long lol \"),\n",
       " ('POS',\n",
       "  \"@Twyst There, there...it'll be okay. Just give the new guy a chance. \"),\n",
       " ('POS',\n",
       "  '@ddlovato aww lol, r u on tour wid da jo bros ?? Pleasee sayy hii to mee, wudd make me soo happy  x'),\n",
       " ('NEG',\n",
       "  'Just back from the wound care center, the 2 wounds on my lower leg are getting larger. I go back tomorrow.  '),\n",
       " ('POS',\n",
       "  \"@Twisuz ok, i'll go read it! im really excited 4 some reason! lol!  x\"),\n",
       " ('POS',\n",
       "  \"@wstmjonathan cool, so if you could help make that happen, &amp; make sure it happens at least once in houston, that'd be great. k? thanks. \"),\n",
       " ('POS',\n",
       "  \"headed to @xclaviclex's house and then to hollywood -- enjoy ur night guys \"),\n",
       " ('POS',\n",
       "  \"It was fun talking to you again! June 12's the date! Well, not a date but burrito and cherry's day out  sta. cruz &amp; winchester's house! =]\"),\n",
       " ('NEG', 'ive lost my hair mooouse?!  hmmm '),\n",
       " ('POS', '@EASMusic when will we figure out our ridiculous email sitch?!  '),\n",
       " ('POS', 'Oh, that was quick. Here. Have a video!  http://bit.ly/74pWN'),\n",
       " ('NEG',\n",
       "  \"@alfaye Trying to write the one-shot but my plot bunny isn't cooperating well.  Should be up soon though! 40 more days!\"),\n",
       " ('POS', 'is happy the hawks got up '),\n",
       " ('NEG',\n",
       "  \"Not in the mood again. :|  I know its mother's day and all but I'm totally bummed out bcoz of my mom. Don't ask.\"),\n",
       " ('NEG',\n",
       "  'Hopes there is Sprouses People magazine edition  that will cheer her up'),\n",
       " ('POS', 'Lovin Jay Seans Tune- Down....Its Alort! '),\n",
       " ('POS', '@emilysparkle EMILY! YOU FOUND ME! AND NOW I FOUND YOU!  '),\n",
       " ('NEG',\n",
       "  \"@minkus That's crazy... even my small town in ohio has those! I'm sad for you \"),\n",
       " ('NEG', 'Is sad  and now must go back to sleep')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    I am training a natural language processing model but dont have enough data. It is your job to generate more, new, and unique samples\\n    of data like the ones pasted below. What you generate should be representitive of what might be found on twitter. Use appropriate slang, humor, and give a wide varity\\n    of types of samples (i.e, talking about different topics). Pased below is a small representative sample which should inspire you, as well as their labels. Use the type of wording and writing style of \\n    these tweets. Return *only* the requested JSON response, in the same format as below, with your assigned labels to your generated samples. I want you to generate {N} samples.\\n\\n    Your returned format should look like this:\\n    {\\n        \\'content of tweet 1\\': \\'POS\\',\\n        \\'content of tweet 2\\': \\'NEG\\',\\n        ...\\n        \\n    }\\n    \\n    Here is the representative sample of tweets. Please do not use emojis in your samples.\\n\\n\\n\\n    [(\\'NEG\\', \\'Tired. Dogs kept me awake most of the night \\'), (\\'NEG\\', \"I hurt my thumb, can\\'t... twitter... as ... much... \"), (\\'POS\\', \\'@Pete_Brown it runs on a mutated version of Graffiti CMS \\'), (\\'NEG\\', \\'@David1969 we believe our 8 month old baby could just be starting to teethe!!! 6 months of this does not sound good \\'), (\\'POS\\', \\'@Freshmen08, i thought so  i pleased acquaintance wit u lol\\'), (\\'NEG\\', \"Smoke didn\\'t eat the wet food so guess we\\'re still going to vet. \"), (\\'POS\\', \\'@delwilliams Because cheap stuff never wears out! \\'), (\\'NEG\\', \\'Bummed my 15-yr highschool reunion got cancelled. \\'), (\\'POS\\', \\'@13tales 7pm at osaka ohsho if you want to join us for gyoza night! \\'), (\\'POS\\', \\'i can haz pretty flowerz background \\'), (\\'POS\\', \\'10 little girls ages 3-4 in the house for my daugthers birthday, treasure hunt done, just trying to stay on top of the situation \\'), (\\'POS\\', \\'@MusicxLover hey guess what i forgot today. \\'), (\\'NEG\\', \"@BeerAdvocate aww darn missed you guys!   Had a blast at the #ACBF, though. Sure I\\'ll see you soon... Hair of the Dog, perhaps...\"), (\\'POS\\', \\'@ImaPacifist maybe if you were hookin you have 6k in real money,  just a thought \\'), (\\'POS\\', \"@Pomtidom Haha. I dunno. I\\'ve had the CIA and countless other security agencies on my blog too \"), (\\'POS\\', \\'greg pritchard \\'), (\\'POS\\', \\'@XboxHornetNews OMG what a piece of crap \\'), (\\'POS\\', \\'@AdamTyson Oh I miss Charlie! He so loved Clare!! Of course I am in love with Sawyer, but I also love Locke, Desmond, sayeed and sun! \\'), (\\'NEG\\', \"@RogueMessiah Yeah, well if kids, especially really young ones, don\\'t learn to be self-entertained they become dependent on adults 4 fun \"), (\\'POS\\', \\'Smoking cigarettes and working hard \\')]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPrompt(50, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = queryGPT(getPrompt(5, samples))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Red, blue, green'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queryGPT(\"name three colors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"gpt.json\", \"r\") as js:\n",
    "    data = json.load(js)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data)\n",
    "len(list(filter(lambda x: x == \"POS\", list(data.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37083333333333335"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 151 / 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
